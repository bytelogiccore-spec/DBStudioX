//! Data Migration Commands
//!
//! Handles importing and exporting data (CSV, JSON).

use crate::state::AppState;
use crate::utils::{AppError, AppResult};
use serde::{Deserialize, Serialize};
use std::fs::File;
use std::io::{BufReader, BufWriter, Write};

/// Migration statistics
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct MigrationStats {
    pub rows_processed: usize,
    pub success: bool,
    pub message: String,
}

/// Import data from file into table
#[tauri::command]
pub async fn import_data(
    state: tauri::State<'_, std::sync::Arc<AppState>>,
    connection_id: String,
    table_name: String,
    file_path: String,
    format: String,
) -> AppResult<MigrationStats> {
    log::info!("Importing data from {} to table {}", file_path, table_name);

    let db_handle = state
        .get_db_handle(&connection_id)
        .ok_or_else(|| AppError::NotFound(format!("Connection not found: {}", connection_id)))?;

    let rows_processed = match format.to_lowercase().as_str() {
        "csv" => import_csv(&db_handle, &table_name, &file_path).await?,
        "json" => import_json(&db_handle, &table_name, &file_path).await?,
        "sql" => import_sql(&db_handle, &file_path).await?,
        _ => {
            return Err(AppError::BadRequest(format!(
                "Unsupported format: {}",
                format
            )))
        }
    };

    Ok(MigrationStats {
        rows_processed,
        success: true,
        message: format!("Successfully imported rows (approx: {})", rows_processed),
    })
}

/// Export table data to file
#[tauri::command]
pub async fn export_data(
    state: tauri::State<'_, std::sync::Arc<AppState>>,
    connection_id: String,
    table_name: String,
    file_path: String,
    format: String,
) -> AppResult<MigrationStats> {
    log::info!("Exporting table {} to {}", table_name, file_path);

    let db_handle = state
        .get_db_handle(&connection_id)
        .ok_or_else(|| AppError::NotFound(format!("Connection not found: {}", connection_id)))?;

    let rows_processed = match format.to_lowercase().as_str() {
        "csv" => export_csv(&db_handle, &table_name, &file_path).await?,
        "json" => export_json(&db_handle, &table_name, &file_path).await?,
        "sql" => export_sql(&db_handle, &table_name, &file_path).await?,
        _ => {
            return Err(AppError::BadRequest(format!(
                "Unsupported format: {}",
                format
            )))
        }
    };

    Ok(MigrationStats {
        rows_processed,
        success: true,
        message: format!("Successfully exported {} rows", rows_processed),
    })
}

async fn import_sql(
    db_handle: &std::sync::Arc<parking_lot::Mutex<crate::sqlite3x::wrapper::Database>>,
    file_path: &str,
) -> AppResult<usize> {
    let sql_content = std::fs::read_to_string(file_path)
        .map_err(|e| AppError::IoError(format!("Failed to read SQL file: {}", e)))?;

    let db = db_handle.lock();

    // We use execute_batch for SQL dumps which might contain multiple statements
    db.execute_batch(&sql_content)
        .map_err(|e| AppError::QueryError(format!("Failed to execute batch SQL: {:?}", e)))?;

    // We don't know exactly how many rows, assume 1 operation or count newlines roughly
    Ok(sql_content.lines().count())
}

async fn export_sql(
    db_handle: &std::sync::Arc<parking_lot::Mutex<crate::sqlite3x::wrapper::Database>>,
    table_name: &str,
    file_path: &str,
) -> AppResult<usize> {
    let db = db_handle.lock();

    let sql = format!("SELECT * FROM \"{}\"", table_name);
    let result = db
        .query(&sql)
        .map_err(|e| AppError::QueryError(format!("{:?}", e)))?;

    let file = File::create(file_path)
        .map_err(|e| AppError::IoError(format!("Failed to create SQL file: {}", e)))?;
    let mut writer = BufWriter::new(file);

    // Write header comment
    writeln!(writer, "-- Export of table '{}'", table_name)
        .map_err(|e| AppError::IoError(format!("Write error: {}", e)))?;
    writeln!(
        writer,
        "-- Generated by DBStudioX on {}",
        chrono::Local::now()
    )
    .map_err(|e| AppError::IoError(format!("Write error: {}", e)))?;

    writeln!(writer, "BEGIN TRANSACTION;")
        .map_err(|e| AppError::IoError(format!("Write error: {}", e)))?;

    let columns_str = result
        .columns
        .iter()
        .map(|c| format!("\"{}\"", c))
        .collect::<Vec<_>>()
        .join(", ");

    let mut count = 0;

    for row in result.rows {
        let values: Vec<String> = row
            .iter()
            .map(|v| match v {
                serde_json::Value::Null => "NULL".to_string(),
                serde_json::Value::Number(n) => n.to_string(),
                serde_json::Value::Bool(b) => (if *b { "1" } else { "0" }).to_string(),
                serde_json::Value::String(s) => format!("'{}'", s.replace("'", "''")),
                serde_json::Value::Array(a) => format!(
                    "'{}'",
                    serde_json::to_string(a)
                        .unwrap_or_default()
                        .replace("'", "''")
                ),
                serde_json::Value::Object(o) => format!(
                    "'{}'",
                    serde_json::to_string(o)
                        .unwrap_or_default()
                        .replace("'", "''")
                ),
            })
            .collect();

        let insert_sql = format!(
            "INSERT INTO \"{}\" ({}) VALUES ({});",
            table_name,
            columns_str,
            values.join(", ")
        );

        writeln!(writer, "{}", insert_sql)
            .map_err(|e| AppError::IoError(format!("Write error: {}", e)))?;

        count += 1;
    }

    writeln!(writer, "COMMIT;").map_err(|e| AppError::IoError(format!("Write error: {}", e)))?;

    writer
        .flush()
        .map_err(|e| AppError::IoError(format!("Failed to flush file: {}", e)))?;

    Ok(count)
}

async fn import_csv(
    db_handle: &std::sync::Arc<parking_lot::Mutex<crate::sqlite3x::wrapper::Database>>,
    table_name: &str,
    file_path: &str,
) -> AppResult<usize> {
    let mut reader = csv::Reader::from_path(file_path)
        .map_err(|e| AppError::IoError(format!("Failed to open CSV: {}", e)))?;

    let headers = reader
        .headers()
        .map_err(|e| AppError::IoError(format!("Failed to read headers: {}", e)))?
        .clone();

    // Prepare insert statement
    // INSERT INTO table (col1, col2) VALUES (?, ?)
    let columns: Vec<&str> = headers.iter().collect();
    // let placeholders: Vec<&str> = vec!["?"; columns.len()]; // Unused if manual format

    // ... (rest of CSV logic)

    let db = db_handle.lock();

    db.execute("BEGIN TRANSACTION")
        .map_err(|e| AppError::QueryError(format!("Failed to begin transaction: {:?}", e)))?;

    let mut count = 0;

    for result in reader.records() {
        let record = result.map_err(|e| AppError::IoError(format!("Invalid CSV record: {}", e)))?;

        let mut params = Vec::new();
        for field in record.iter() {
            params.push(serde_json::Value::String(field.to_string()));
        }

        let placeholders: Vec<String> = (0..columns.len()).map(|_| "?".to_string()).collect();
        let row_sql = format!(
            "INSERT INTO \"{}\" ({}) VALUES ({})",
            table_name,
            columns.join(", "),
            placeholders.join(", ")
        );

        db.execute_with_params(&row_sql, params).map_err(|e| {
            AppError::QueryError(format!("Insert failed at row {}: {:?}", count + 1, e))
        })?;

        count += 1;
    }

    db.execute("COMMIT")
        .map_err(|e| AppError::QueryError(format!("Failed to commit transaction: {:?}", e)))?;

    Ok(count)
}

async fn import_json(
    db_handle: &std::sync::Arc<parking_lot::Mutex<crate::sqlite3x::wrapper::Database>>,
    table_name: &str,
    file_path: &str,
) -> AppResult<usize> {
    // ...
    // Reuse existing implementation, just put it here for completeness or rely on git applying changes correctly
    // Since this is replace tool, I need to provide full content for changed blocks or specific ranges.
    // I will use StartLine/EndLine logic to be safe, but replacing 35-73 (data functions) and adding new ones at the end.
    // Actually, I can replace the WHOLE commands logic if I want.
    // Let's replace lines 35-73 with new match blocks, AND append new functions.
    // But append requires knowing end of file. I will use `replace_file_content` targeting the top match logic and then use `write_to_file` or another replaces.
    // Wait, replacing lines 35-40 and 62-67 is feasible. And adding functions.
    // But adding new functions at the end requires finding end of file.

    // Let's replace the whole file from `MigrationStats` downwards to be safe and clean.
    // But `import_csv` and `import_json` are long.
    // I will use a precise replace for the `match` blocks and append functions at the end of the file.
    // Actually, appending via replace is tricky (TargetContent needs to be known).
    // I'll assume `import_json` ends at line 231.
    // I'll replace from `import_csv` start (line 75) to the end of file.

    // Oh wait, I can just replace everything from line 35 to the end if I paste everything back.
    // Let's do that.

    // Wait, I need to re-implement `import_csv` and others to include them in the replace block if I wipe them out.
    // That's fine.

    let file = File::open(file_path)
        .map_err(|e| AppError::IoError(format!("Failed to open JSON: {}", e)))?;
    let reader = BufReader::new(file);

    let json_data: serde_json::Value = serde_json::from_reader(reader)
        .map_err(|e| AppError::IoError(format!("Failed to parse JSON: {}", e)))?;

    let array = json_data
        .as_array()
        .ok_or_else(|| AppError::BadRequest("JSON root must be an array".to_string()))?;

    if array.is_empty() {
        return Ok(0);
    }

    let db = db_handle.lock();
    db.execute("BEGIN TRANSACTION")
        .map_err(|e| AppError::QueryError(format!("Failed to begin transaction: {:?}", e)))?;

    // Validate all items are objects first to return correct error type
    for (i, item) in array.iter().enumerate() {
        if !item.is_object() {
            return Err(AppError::BadRequest(format!(
                "Item at index {} is not an object",
                i
            )));
        }
    }

    let first_obj = array[0]
        .as_object()
        .expect("Checked array is not empty and items are objects");

    let columns: Vec<String> = first_obj.keys().cloned().collect();
    let placeholders: Vec<String> = (0..columns.len()).map(|_| "?".to_string()).collect();
    let row_sql = format!(
        "INSERT INTO \"{}\" ({}) VALUES ({})",
        table_name,
        columns.join(", "),
        placeholders.join(", ")
    );

    let params_iter = array
        .iter()
        .map(|item| -> Result<Vec<serde_json::Value>, String> {
            // Safe to unwrap here as we validated above
            let obj = item.as_object().unwrap();

            let mut params = Vec::with_capacity(columns.len());
            for col in &columns {
                params.push(obj.get(col).cloned().unwrap_or(serde_json::Value::Null));
            }
            Ok(params)
        });

    let count = db
        .execute_batch_params(&row_sql, params_iter)
        .map_err(|e| AppError::QueryError(format!("Batch insert failed: {:?}", e)))?;

    db.execute("COMMIT")
        .map_err(|e| AppError::QueryError(format!("Failed to commit transaction: {:?}", e)))?;

    Ok(count)
}

async fn export_csv(
    db_handle: &std::sync::Arc<parking_lot::Mutex<crate::sqlite3x::wrapper::Database>>,
    table_name: &str,
    file_path: &str,
) -> AppResult<usize> {
    let db = db_handle.lock();

    let sql = format!("SELECT * FROM \"{}\"", table_name);
    let result = db
        .query(&sql)
        .map_err(|e| AppError::QueryError(format!("{:?}", e)))?;

    let mut wtr = csv::Writer::from_path(file_path)
        .map_err(|e| AppError::IoError(format!("Failed to create CSV: {}", e)))?;

    // Write headers
    wtr.write_record(&result.columns)
        .map_err(|e| AppError::IoError(format!("Failed to write headers: {}", e)))?;

    let mut count = 0;
    for row in result.rows {
        let record: Vec<String> = row
            .iter()
            .map(|v| match v {
                serde_json::Value::String(s) => s.clone(),
                serde_json::Value::Null => "".to_string(),
                other => other.to_string(),
            })
            .collect();

        wtr.write_record(&record)
            .map_err(|e| AppError::IoError(format!("Failed to write record: {}", e)))?;
        count += 1;
    }

    wtr.flush()
        .map_err(|e| AppError::IoError(format!("Failed to flush CSV: {}", e)))?;

    Ok(count)
}

async fn export_json(
    db_handle: &std::sync::Arc<parking_lot::Mutex<crate::sqlite3x::wrapper::Database>>,
    table_name: &str,
    file_path: &str,
) -> AppResult<usize> {
    let db = db_handle.lock();

    let sql = format!("SELECT * FROM \"{}\"", table_name);
    let result = db
        .query(&sql)
        .map_err(|e| AppError::QueryError(format!("{:?}", e)))?;

    let mut rows_as_maps = Vec::new();

    for row in result.rows {
        let mut map = serde_json::Map::new();
        for (i, val) in row.iter().enumerate() {
            if i < result.columns.len() {
                map.insert(result.columns[i].clone(), val.clone());
            }
        }
        rows_as_maps.push(serde_json::Value::Object(map));
    }

    let json_output = serde_json::Value::Array(rows_as_maps);
    let count = json_output.as_array().map(|a| a.len()).unwrap_or(0);

    let file = File::create(file_path)
        .map_err(|e| AppError::IoError(format!("Failed to create JSON file: {}", e)))?;
    let mut writer = BufWriter::new(file);

    serde_json::to_writer_pretty(&mut writer, &json_output)
        .map_err(|e| AppError::IoError(format!("Failed to write JSON: {}", e)))?;

    writer
        .flush()
        .map_err(|e| AppError::IoError(format!("Failed to flush JSON: {}", e)))?;

    Ok(count)
}

/// Copy table from one database to another
#[tauri::command]
pub async fn copy_table(
    state: tauri::State<'_, std::sync::Arc<AppState>>,
    source_db_id: String,
    source_table: String,
    target_db_id: String,
    target_table: String,
    with_data: bool,
) -> AppResult<MigrationStats> {
    log::info!(
        "Copying table {} from {} to {} (target: {})",
        source_table,
        source_db_id,
        target_db_id,
        target_table
    );

    if source_db_id == target_db_id && source_table == target_table {
        return Err(AppError::BadRequest(
            "Source and target table cannot be identical in the same database.".to_string(),
        ));
    }

    let source_db_handle = state.get_db_handle(&source_db_id).ok_or_else(|| {
        AppError::NotFound(format!("Source connection not found: {}", source_db_id))
    })?;

    let target_db_handle = state.get_db_handle(&target_db_id).ok_or_else(|| {
        AppError::NotFound(format!("Target connection not found: {}", target_db_id))
    })?;

    // 1. Get CREATE SQL from source
    let create_sql = {
        let db = source_db_handle.lock();
        let query_sql = "SELECT sql FROM sqlite_master WHERE type='table' AND name = ?";
        let result = db
            .query_with_params(
                query_sql,
                vec![serde_json::Value::String(source_table.clone())],
            )
            .map_err(|e| AppError::QueryError(format!("Failed to fetch table schema: {:?}", e)))?;

        if result.rows.is_empty() {
            return Err(AppError::NotFound(format!(
                "Source table '{}' not found",
                source_table
            )));
        }

        result.rows[0][0]
            .as_str()
            .ok_or_else(|| AppError::QueryError("Table schema SQL is null".to_string()))?
            .to_string()
    };

    // 2. Modify SQL for target table name
    // Replace "CREATE TABLE "Source"" with "CREATE TABLE "Target""
    // or "CREATE TABLE Source" -> "CREATE TABLE Target"
    // Use simple heuristic: Replace the source table name string with target table name,
    // respecting quotes if present.
    // If source has "source_table", we look for "source_table".
    // This is fragile if column names match table name.
    // Better: Regex `CREATE TABLE\s+(?:"?{}\"?)\s*`
    // Manual find:
    let new_create_sql = create_sql.replacen(&source_table, &target_table, 1);
    // This is minimal. If source is `CREATE TABLE "tbl"`, and we replace `tbl` -> `new`, we get `CREATE TABLE "new"`.
    // If source is `CREATE TABLE tbl`, we get `CREATE TABLE new`.
    // Only risk: `CREATE TABLE tbl (tbl TEXT)` -> `CREATE TABLE new (new TEXT)`.
    // We should only replace the FIRST occurrence which is usually the table name.

    // 3. Create table in target
    {
        let db = target_db_handle.lock();
        db.execute(&new_create_sql)
            .map_err(|e| AppError::QueryError(format!("Failed to create target table: {:?}", e)))?;
    }

    let mut rows_processed = 0;

    // 4. Copy Data
    if with_data {
        // Read from source
        let source_data = {
            let db = source_db_handle.lock();
            db.query(&format!("SELECT * FROM \"{}\"", source_table))
                .map_err(|e| AppError::QueryError(format!("Failed to read source data: {:?}", e)))?
        };

        let columns_str = source_data
            .columns
            .iter()
            .map(|c| format!("\"{}\"", c))
            .collect::<Vec<_>>()
            .join(", ");

        let db = target_db_handle.lock();
        db.execute("BEGIN TRANSACTION").ok(); // Ignore error if already in tx (unlikely)

        for row in source_data.rows {
            let placeholders: Vec<String> = (0..source_data.columns.len())
                .map(|_| "?".to_string())
                .collect();
            let insert_sql = format!(
                "INSERT INTO \"{}\" ({}) VALUES ({})",
                target_table,
                columns_str,
                placeholders.join(", ")
            );

            if let Err(e) = db.execute_with_params(&insert_sql, row) {
                log::error!("Failed to insert row: {:?}", e);
                db.execute("ROLLBACK").ok();
                return Err(AppError::QueryError(format!(
                    "Copy failed at row {}: {:?}",
                    rows_processed + 1,
                    e
                )));
            }

            rows_processed += 1;
        }

        db.execute("COMMIT")
            .map_err(|e| AppError::QueryError(format!("Failed to commit transaction: {:?}", e)))?;
    }

    Ok(MigrationStats {
        rows_processed,
        success: true,
        message: format!("Table copied successfully ({} rows)", rows_processed),
    })
}
